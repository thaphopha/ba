```json
[
  {
    "arxiv_id": "2504_08999v1",
    "title": "MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context\n  Protocol Servers",
    "summary": "Large Language Models (LLMs) are increasingly augmented with external tools\nthrough standardized interfaces like the Model Context Protocol (MCP). However,\ncurrent MCP implementations face critical limitations: they typically require\nlocal process execution through STDIO transports, making them impractical for\nresource-constrained environments like mobile devices, web browsers, and edge\ncomputing. We present MCP Bridge, a lightweight RESTful proxy that connects to\nmultiple MCP servers and exposes their capabilities through a unified API.\nUnlike existing solutions, MCP Bridge is fully LLM-agnostic, supporting any\nbackend regardless of vendor. The system implements a risk-based execution\nmodel with three security levels standard execution, confirmation workflow, and\nDocker isolation while maintaining backward compatibility with standard MCP\nclients. Complementing this server-side infrastructure is a Python based MCP\nGemini Agent that facilitates natural language interaction with MCP tools. The\nevaluation demonstrates that MCP Bridge successfully addresses the constraints\nof direct MCP connections while providing enhanced security controls and\ncross-platform compatibility, enabling sophisticated LLM-powered applications\nin previously inaccessible environments",
    "authors": [
      "Arash Ahmadi",
      "Sarah Sharif",
      "Yaser M. Banad"
    ],
    "published_date": "2025-04-11T22:19:48Z",
    "pdf_url": "http://arxiv.org/pdf/2504.08999v1",
    "citation": "Ahmadi, A., Sharif, S., & Banad, Y. M. (2025). MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context\n  Protocol Servers. arXiv. https://arxiv.org/abs/2504.08999v1",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2508_13220v1",
    "title": "MCPSecBench: A Systematic Security Benchmark and Playground for Testing\n  Model Context Protocols",
    "summary": "Large Language Models (LLMs) are increasingly integrated into real-world\napplications via the Model Context Protocol (MCP), a universal, open standard\nfor connecting AI agents with data sources and external tools. While MCP\nenhances the capabilities of LLM-based agents, it also introduces new security\nrisks and expands their attack surfaces. In this paper, we present the first\nsystematic taxonomy of MCP security, identifying 17 attack types across 4\nprimary attack surfaces. We introduce MCPSecBench, a comprehensive security\nbenchmark and playground that integrates prompt datasets, MCP servers, MCP\nclients, and attack scripts to evaluate these attacks across three major MCP\nproviders. Our benchmark is modular and extensible, allowing researchers to\nincorporate custom implementations of clients, servers, and transport protocols\nfor systematic security assessment. Experimental results show that over 85% of\nthe identified attacks successfully compromise at least one platform, with core\nvulnerabilities universally affecting Claude, OpenAI, and Cursor, while\nprompt-based and tool-centric attacks exhibit considerable variability across\ndifferent hosts and models. Overall, MCPSecBench standardizes the evaluation of\nMCP security and enables rigorous testing across all MCP layers.",
    "authors": [
      "Yixuan Yang",
      "Daoyuan Wu",
      "Yufan Chen"
    ],
    "published_date": "2025-08-17T11:49:16Z",
    "pdf_url": "http://arxiv.org/pdf/2508.13220v1",
    "citation": "Yang, Y., Wu, D., & Chen, Y. (2025). MCPSecBench: A Systematic Security Benchmark and Playground for Testing\n  Model Context Protocols. arXiv. https://arxiv.org/abs/2508.13220v1",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2508_19239v1",
    "title": "Model Context Protocols in Adaptive Transport Systems: A Survey",
    "summary": "The rapid expansion of interconnected devices, autonomous systems, and AI\napplications has created severe fragmentation in adaptive transport systems,\nwhere diverse protocols and context sources remain isolated. This survey\nprovides the first systematic investigation of the Model Context Protocol (MCP)\nas a unifying paradigm, highlighting its ability to bridge protocol-level\nadaptation with context-aware decision making. Analyzing established\nliterature, we show that existing efforts have implicitly converged toward\nMCP-like architectures, signaling a natural evolution from fragmented solutions\nto standardized integration frameworks. We propose a five-category taxonomy\ncovering adaptive mechanisms, context-aware frameworks, unification models,\nintegration strategies, and MCP-enabled architectures. Our findings reveal\nthree key insights: traditional transport protocols have reached the limits of\nisolated adaptation, MCP's client-server and JSON-RPC structure enables\nsemantic interoperability, and AI-driven transport demands integration\nparadigms uniquely suited to MCP. Finally, we present a research roadmap\npositioning MCP as a foundation for next-generation adaptive, context-aware,\nand intelligent transport infrastructures.",
    "authors": [
      "Gaurab Chhetri",
      "Shriyank Somvanshi",
      "Md Monzurul Islam",
      "Shamyo Brotee",
      "Mahmuda Sultana Mimi",
      "Dipti Koirala",
      "Biplov Pandey",
      "Subasish Das"
    ],
    "published_date": "2025-08-26T17:58:56Z",
    "pdf_url": "http://arxiv.org/pdf/2508.19239v1",
    "citation": "Chhetri, G., Somvanshi, S., Islam, M. M., Brotee, S., Mimi, M. S., Koirala, D., Pandey, B., & Das, S. (2025). Model Context Protocols in Adaptive Transport Systems: A Survey. arXiv. https://arxiv.org/abs/2508.19239v1",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2508_07575v1",
    "title": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool\n  Use Benchmark",
    "summary": "LLMs' capabilities are enhanced by using function calls to integrate various\ndata sources or API results into the context window. Typical tools include\nsearch, web crawlers, maps, financial data, file systems, and browser usage,\netc. Integrating these data sources or functions requires a standardized\nmethod. The Model Context Protocol (MCP) provides a standardized way to supply\ncontext to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use\nabilities suffer from several issues. First, there's a lack of comprehensive\ndatasets or benchmarks to evaluate various MCP tools. Second, the diverse\nformats of response from MCP tool call execution further increase the\ndifficulty of evaluation. Additionally, unlike existing tool-use benchmarks\nwith high success rates in functions like programming and math functions, the\nsuccess rate of real-world MCP tool is not guaranteed and varies across\ndifferent MCP servers. Furthermore, the LLMs' context window also limits the\nnumber of available tools that can be called in a single run, because the\ntextual descriptions of tool and the parameters have long token length for an\nLLM to process all at once. To help address the challenges of evaluating LLMs'\nperformance on calling MCP tools, we propose MCPToolBench++, a large-scale,\nmulti-domain AI Agent tool use benchmark. As of July 2025, this benchmark is\nbuild upon marketplace of over 4k MCP servers from more than 40 categories,\ncollected from the MCP marketplaces and GitHub communities. The datasets\nconsist of both single-step and multi-step tool calls across different\ncategories. We evaluated SOTA LLMs with agentic abilities on this benchmark and\nreported the results.",
    "authors": [
      "Shiqing Fan",
      "Xichen Ding",
      "Liang Zhang",
      "Linjian Mo"
    ],
    "published_date": "2025-08-11T03:16:02Z",
    "pdf_url": "http://arxiv.org/pdf/2508.07575v1",
    "citation": "Fan, S., Ding, X., Zhang, L., & Mo, L. (2025). MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool\n  Use Benchmark. arXiv. https://arxiv.org/abs/2508.07575v1",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2504_12757v2",
    "title": "MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI\n  System",
    "summary": "As Agentic AI gain mainstream adoption, the industry invests heavily in model\ncapabilities, achieving rapid leaps in reasoning and quality. However, these\nsystems remain largely confined to data silos, and each new integration\nrequires custom logic that is difficult to scale. The Model Context Protocol\n(MCP) addresses this challenge by defining a universal, open standard for\nsecurely connecting AI-based applications (MCP clients) to data sources (MCP\nservers). However, the flexibility of the MCP introduces new risks, including\nmalicious tool servers and compromised data integrity. We present MCP Guardian,\na framework that strengthens MCP-based communication with authentication,\nrate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning.\nThrough real-world scenarios and empirical testing, we demonstrate how MCP\nGuardian effectively mitigates attacks and ensures robust oversight with\nminimal overheads. Our approach fosters secure, scalable data access for AI\nassistants, underscoring the importance of a defense-in-depth approach that\nenables safer and more transparent innovation in AI-driven environments.",
    "authors": [
      "Sonu Kumar",
      "Anubhav Girdhar",
      "Ritesh Patil",
      "Divyansh Tripathi"
    ],
    "published_date": "2025-04-17T08:49:10Z",
    "pdf_url": "http://arxiv.org/pdf/2504.12757v2",
    "citation": "Kumar, S., Girdhar, A., Patil, R., & Tripathi, D. (2025). MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI\n  System. arXiv. https://arxiv.org/abs/2504.12757v2",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2504_03767v2",
    "title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major\n  Security Exploits",
    "summary": "To reduce development overhead and enable seamless integration between\npotential components comprising any given generative AI application, the Model\nContext Protocol (MCP) (Anthropic, 2024) has recently been released and\nsubsequently widely adopted. The MCP is an open protocol that standardizes API\ncalls to large language models (LLMs), data sources, and agentic tools. By\nconnecting multiple MCP servers, each defined with a set of tools, resources,\nand prompts, users are able to define automated workflows fully driven by LLMs.\nHowever, we show that the current MCP design carries a wide range of security\nrisks for end users. In particular, we demonstrate that industry-leading LLMs\nmay be coerced into using MCP tools to compromise an AI developer's system\nthrough various attacks, such as malicious code execution, remote access\ncontrol, and credential theft. To proactively mitigate these and related\nattacks, we introduce a safety auditing tool, MCPSafetyScanner, the first\nagentic tool to assess the security of an arbitrary MCP server. MCPScanner uses\nseveral agents to (a) automatically determine adversarial samples given an MCP\nserver's tools and resources; (b) search for related vulnerabilities and\nremediations based on those samples; and (c) generate a security report\ndetailing all findings. Our work highlights serious security issues with\ngeneral-purpose agentic workflows while also providing a proactive tool to\naudit MCP server safety and address detected vulnerabilities before deployment.\n  The described MCP server auditing tool, MCPSafetyScanner, is freely available\nat: https://github.com/johnhalloran321/mcpSafetyScanner",
    "authors": [
      "Brandon Radosevich",
      "John Halloran"
    ],
    "published_date": "2025-04-02T21:46:02Z",
    "pdf_url": "http://arxiv.org/pdf/2504.03767v2",
    "citation": "Radosevich, B. & Halloran, J. (2025). MCP Safety Audit: LLMs with the Model Context Protocol Allow Major\n  Security Exploits. arXiv. https://arxiv.org/abs/2504.03767v2",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2504_19997v1",
    "title": "Simplified and Secure MCP Gateways for Enterprise AI Integration",
    "summary": "The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.",
    "authors": [
      "Ivo Brett"
    ],
    "published_date": "2025-04-28T17:17:42Z",
    "pdf_url": "http://arxiv.org/pdf/2504.19997v1",
    "citation": "Brett, I. (2025). Simplified and Secure MCP Gateways for Enterprise AI Integration. arXiv. https://arxiv.org/abs/2504.19997v1",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2506_13538v4",
    "title": "Model Context Protocol (MCP) at First Glance: Studying the Security and\n  Maintainability of MCP Servers",
    "summary": "Although Foundation Models (FMs), such as GPT-4, are increasingly used in\ndomains like finance and software engineering, reliance on textual interfaces\nlimits these models' real-world interaction. To address this, FM providers\nintroduced tool calling-triggering a proliferation of frameworks with distinct\ntool interfaces. In late 2024, Anthropic introduced the Model Context Protocol\n(MCP) to standardize this tool ecosystem, which has become the de facto\nstandard with over eight million weekly SDK downloads. Despite its adoption,\nMCP's AI-driven, non-deterministic control flow introduces new risks to\nsustainability, security, and maintainability, warranting closer examination.\n  Towards this end, we present the first large-scale empirical study of MCP\nservers. Using state-of-the-art health metrics and a hybrid analysis pipeline,\ncombining a general-purpose static analysis tool with an MCP-specific scanner,\nwe evaluate 1,899 open-source MCP servers to assess their health, security, and\nmaintainability. Despite MCP servers demonstrating strong health metrics, we\nidentify eight distinct vulnerabilities - only three overlapping with\ntraditional software vulnerabilities. Additionally, 7.2% of servers contain\ngeneral vulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regarding\nmaintainability, while 66% exhibit code smells, 14.4% contain nine bug patterns\noverlapping with traditional open-source software projects. These findings\nhighlight the need for MCP-specific vulnerability detection techniques while\nreaffirming the value of traditional analysis and refactoring practices.",
    "authors": [
      "Mohammed Mehedi Hasan",
      "Hao Li",
      "Emad Fallahzadeh",
      "Gopi Krishnan Rajbahadur",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "published_date": "2025-06-16T14:26:37Z",
    "pdf_url": "http://arxiv.org/pdf/2506.13538v4",
    "citation": "Hasan, M. M., Li, H., Fallahzadeh, E., Rajbahadur, G. K., Adams, B., & Hassan, A. E. (2025). Model Context Protocol (MCP) at First Glance: Studying the Security and\n  Maintainability of MCP Servers. arXiv. https://arxiv.org/abs/2506.13538v4",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2503_23278v2",
    "title": "Model Context Protocol (MCP): Landscape, Security Threats, and Future\n  Research Directions",
    "summary": "The Model Context Protocol (MCP) is a standardized interface designed to\nenable seamless interaction between AI models and external tools and resources,\nbreaking down data silos and facilitating interoperability across diverse\nsystems. This paper provides a comprehensive overview of MCP, focusing on its\ncore components, workflow, and the lifecycle of MCP servers, which consists of\nthree key phases: creation, operation, and update. We analyze the security and\nprivacy risks associated with each phase and propose strategies to mitigate\npotential threats. The paper also examines the current MCP landscape, including\nits adoption by industry leaders and various use cases, as well as the tools\nand platforms supporting its integration. We explore future directions for MCP,\nhighlighting the challenges and opportunities that will influence its adoption\nand evolution within the broader AI ecosystem. Finally, we offer\nrecommendations for MCP stakeholders to ensure its secure and sustainable\ndevelopment as the AI landscape continues to evolve.",
    "authors": [
      "Xinyi Hou",
      "Yanjie Zhao",
      "Shenao Wang",
      "Haoyu Wang"
    ],
    "published_date": "2025-03-30T01:58:22Z",
    "pdf_url": "http://arxiv.org/pdf/2503.23278v2",
    "citation": "Hou, X., Zhao, Y., Wang, S., & Wang, H. (2025). Model Context Protocol (MCP): Landscape, Security Threats, and Future\n  Research Directions. arXiv. https://arxiv.org/abs/2503.23278v2",
    "year": 2025,
    "journal": null,
    "doi": null
  },
  {
    "arxiv_id": "2506_13666v1",
    "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered\n  Agent Systems",
    "summary": "The development of large language models (LLMs) has entered in a\nexperience-driven era, flagged by the emergence of environment feedback-driven\nlearning via reinforcement learning and tool-using agents. This encourages the\nemergence of model context protocol (MCP), which defines the standard on how\nshould a LLM interact with external services, such as \\api and data. However,\nas MCP becomes the de facto standard for LLM agent systems, it also introduces\nnew safety risks. In particular, MCP introduces third-party services, which are\nnot controlled by the LLM developers, into the agent systems. These third-party\nMCP services provider are potentially malicious and have the economic\nincentives to exploit vulnerabilities and sabotage user-agent interactions. In\nthis position paper, we advocate the research community in LLM safety to pay\nclose attention to the new safety risks issues introduced by MCP, and develop\nnew techniques to build safe MCP-powered agent systems. To establish our\nposition, we argue with three key parts. (1) We first construct \\framework, a\ncontrolled framework to examine safety issues in MCP-powered agent systems. (2)\nWe then conduct a series of pilot experiments to demonstrate the safety risks\nin MCP-powered agent systems is a real threat and its defense is not trivial.\n(3) Finally, we give our outlook by showing a roadmap to build safe MCP-powered\nagent systems. In particular, we would call for researchers to persue the\nfollowing research directions: red teaming, MCP safe LLM development, MCP\nsafety evaluation, MCP safety data accumulation, MCP service safeguard, and MCP\nsafe ecosystem construction. We hope this position paper can raise the\nawareness of the research community in MCP safety and encourage more\nresearchers to join this important research direction. Our code is available at\nhttps://github.com/littlelittlenine/SafeMCP.git.",
    "authors": [
      "Junfeng Fang",
      "Zijun Yao",
      "Ruipeng Wang",
      "Haokai Ma",
      "Xiang Wang",
      "Tat-Seng Chua"
    ],
    "published_date": "2025-06-16T16:24:31Z",
    "pdf_url": "http://arxiv.org/pdf/2506.13666v1",
    "citation": "Fang, J., Yao, Z., Wang, R., Ma, H., Wang, X., & Chua, T. (2025). We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered\n  Agent Systems. arXiv. https://arxiv.org/abs/2506.13666v1",
    "year": 2025,
    "journal": null,
    "doi": null
  }
]
```